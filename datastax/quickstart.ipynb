{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh43dv6rWt8C"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEtnVeSzWt8U"
      },
      "source": [
        "# Quickstart with RAGStack\n",
        "\n",
        "This notebook demonstrates how to set up a simple RAG pipeline with RAGStack. At the end of this notebook, you will have a fully functioning Question/Answer model that can answer questions using your supplied documents.\n",
        "\n",
        "A RAG pipeline requires, at minimum, a vector store, an embedding model, and an LLM. In this tutorial, you will use an Astra DB vector store, an OpenAI embedding model, an OpenAI LLM, and LangChain to orchestrate it all together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeTv3SxNWt8Y"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You will need a vector-enabled Astra database and an OpenAI Account.\n",
        "\n",
        "* Create an [Astra vector database](https://docs.datastax.com/en/astra-serverless/docs/getting-started/create-db-choices.html).\n",
        "* Create an [OpenAI account](https://openai.com/)\n",
        "* Within your database, create an [Astra DB Access Token](https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html) with Database Administrator permissions.\n",
        "* Get your Astra DB Endpoint:\n",
        "  * `https://<ASTRA_DB_ID>-<ASTRA_DB_REGION>.apps.astra.datastax.com`\n",
        "\n",
        "See the [Prerequisites](https://docs.datastax.com/en/ragstack/docs/prerequisites.html) page for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SDcAxAzWt8a"
      },
      "source": [
        "## Setup\n",
        "`ragstack-ai` includes all the packages you need to build a RAG pipeline.\n",
        "\n",
        "`datasets` is used to import a sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true,
        "id": "jG92uyG0Wt8c",
        "nbmake": {
          "post_cell_execute": [
            "from conftest import before_notebook",
            "before_notebook()"
          ]
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ! pip install -q ragstack-ai datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "editable": true,
        "id": "XwFjccyZWt8i",
        "nbmake": {
          "post_cell_execute": [
            "import string\n",
            "import random\n",
            "collection = ''.join(random.choice(string.ascii_lowercase) for _ in range(8))\n"
          ]
        },
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Enter your settings for Astra DB and OpenAI:\n",
        "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = \"https://8540165f-d918-4e01-8140-fbc22be05ca8-us-east-2.apps.astra.datastax.com\"\n",
        "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCUp4tPwWt8l"
      },
      "source": [
        "## Create RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JFGBb9SWt8m"
      },
      "source": [
        "### Embedding Model and Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "editable": true,
        "id": "T4QOs7cJWt8o",
        "outputId": "67820085-8d78-453b-95a0-a08a17c3ed10",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Astra vector store configured\n"
          ]
        }
      ],
      "source": [
        "from langchain_astradb import AstraDBVectorStore\n",
        "from langchain.embeddings import OllamaEmbeddings\n",
        "import os\n",
        "\n",
        "# Configure your embedding model and vector store\n",
        "embedding = OllamaEmbeddings()\n",
        "vstore = AstraDBVectorStore(\n",
        "    collection_name=\"philocollection\",\n",
        "    embedding=embedding,\n",
        "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
        "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
        ")\n",
        "print(\"Astra vector store configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FtfzhBI7Wt8s",
        "outputId": "a232d593-5a1d-4d3c-81b5-d53fba2e8928"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the latest cached version of the dataset since datastax/philosopher-quotes couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'default' at C:\\Users\\sunne\\.cache\\huggingface\\datasets\\datastax___philosopher-quotes\\default\\0.0.0\\3b22a6a8b08fa444426e3c10a8eb5dfb021b472b (last modified on Fri Jun 28 20:15:21 2024).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An example entry:\n",
            "{'author': 'schopenhauer', 'quote': 'Every man takes the limits of his own field of vision for the limits of the world.', 'tags': 'ethics;knowledge'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load a sample dataset\n",
        "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]\n",
        "print(\"An example entry:\")\n",
        "print(philo_dataset[55])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3QoqoIQcWt8u"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "# Constructs a set of documents from your data. Documents can be used as inputs to your vector store.\n",
        "docs = []\n",
        "for entry in philo_dataset:\n",
        "    metadata = {\"author\": entry[\"author\"]}\n",
        "    if entry[\"tags\"]:\n",
        "        # Add metadata tags to the metadata dictionary\n",
        "        for tag in entry[\"tags\"].split(\";\"):\n",
        "            metadata[tag] = \"y\"\n",
        "    # Create a LangChain document with the quote and metadata tags\n",
        "    doc = Document(page_content=entry[\"quote\"], metadata=metadata)\n",
        "    docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Before you heal the body you must first heal the mind', metadata={'author': 'aristotle', 'ethics': 'y'})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JKY4dm3IWt8w",
        "nbmake": {
          "post_cell_execute": [
            "assert len(inserted_ids) > 0"
          ]
        },
        "outputId": "b719b2d1-0c92-4447-eaca-3c0d3c245eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inserted 20 documents.\n"
          ]
        }
      ],
      "source": [
        "# Create embeddings by inserting your documents into the vector store.\n",
        "inserted_ids = vstore.add_documents(docs[:20])\n",
        "print(f\"\\nInserted {len(inserted_ids)} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "editable": true,
        "id": "yYCpevIQWt8y",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': {'documents': [{'_id': 'e372b04d3b8b46cf9fa591cc4fe075c1', 'content': 'The society that loses its grip on the past is in danger, for it produces men who know nothing but the present, and who are not aware that life had been, and could be, different from what it is.', 'metadata': {'author': 'aristotle', 'history': 'y', 'ethics': 'y', 'knowledge': 'y'}}, {'_id': 'e2f57535957b41fcba29718c43e92a60', 'content': 'You are what you do repeatedly.', 'metadata': {'author': 'aristotle'}}, {'_id': 'ce8dadc201bd471a8079b84aeaf5b42d', 'content': 'The quality of life is determined by its activities.', 'metadata': {'author': 'aristotle'}}, {'_id': '9b71e562855f452788a01eae2c9b1652', 'content': 'The man who is truly good and wise will bear with dignity whatever fortune sends, and will always make the best of his circumstances.', 'metadata': {'author': 'aristotle', 'knowledge': 'y', 'ethics': 'y'}}, {'_id': '1865248ab2eb4341a7aec1e57239475e', 'content': 'Anyone who has no need of anybody but himself is either a beast or a God.', 'metadata': {'author': 'aristotle'}}, {'_id': 'adacbb63debd4e88beb30d4cf798faed', 'content': 'Before you heal the body you must first heal the mind', 'metadata': {'author': 'aristotle', 'ethics': 'y'}}, {'_id': 'dc5714263a4c419292eb4f123e0d17c0', 'content': 'The roots of education are bitter, but the fruit is sweet.', 'metadata': {'author': 'aristotle', 'education': 'y', 'knowledge': 'y'}}, {'_id': '286699be95644643afe8f9088c40f2b5', 'content': 'Fortune favours the bold.', 'metadata': {'author': 'aristotle'}}, {'_id': 'c076b89afa724e7e875538c004a80730', 'content': 'Philosophy begins with wonder.', 'metadata': {'author': 'aristotle'}}, {'_id': '198d498d85af429f86afcea734b41ce7', 'content': 'The greatest thing by far is to be a master of metaphor; it is the one thing that cannot be learned from others; and it is also a sign of genius, since a good metaphor implies an intuitive perception of the similarity of the dissimilar.', 'metadata': {'author': 'aristotle'}}, {'_id': 'f42e0cbd88584066badface4c9f43274', 'content': 'The roots of education are bitter, but the fruit is sweet.', 'metadata': {'author': 'aristotle', 'education': 'y', 'knowledge': 'y'}}, {'_id': '5ced405644834073a7118a760408f47c', 'content': \"True happiness comes from gaining insight and growing into your best possible self. Otherwise all you're having is immediate gratification pleasure, which is fleeting and doesn't grow you as a person.\", 'metadata': {'author': 'aristotle', 'knowledge': 'y'}}, {'_id': 'b991daf52a7e4b6e9291dd0d790baad4', 'content': 'Love is composed of a single soul inhabiting two bodies.', 'metadata': {'author': 'aristotle', 'love': 'y'}}, {'_id': '47555586864443838aca6acdd081cdd1', 'content': \"True happiness comes from gaining insight and growing into your best possible self. Otherwise all you're having is immediate gratification pleasure, which is fleeting and doesn't grow you as a person.\", 'metadata': {'author': 'aristotle', 'knowledge': 'y'}}, {'_id': '4aa254bf7b534b9db968a9abeafe0389', 'content': 'Plato is my friend, but truth is a better friend.', 'metadata': {'author': 'aristotle'}}, {'_id': '0919dc3511c44c5c9d0136f2cef62475', 'content': 'The proof that you know something is that you are able to teach it', 'metadata': {'author': 'aristotle', 'education': 'y', 'knowledge': 'y'}}, {'_id': '08a4a4bbdf9e4c918f2529b84d2958a9', 'content': 'The greatest of all pleasures is the pleasure of learning.', 'metadata': {'author': 'aristotle', 'knowledge': 'y', 'education': 'y', 'history': 'y'}}, {'_id': 'b61d7144e302498d92e6a9314374388a', 'content': 'Whatever we learn to do, we learn by actually doing it; men come to be builders, for instance, by building, and harp players by playing the harp. In the same way, by doing just acts we come to be just; by doing self-controlled acts, we come to be self-controlled ; and by doing brave acts, we become brave.', 'metadata': {'author': 'aristotle', 'education': 'y', 'knowledge': 'y'}}, {'_id': '1854ece1bbae4476828650f3fbffd9d3', 'content': 'Love well, be loved and do something of value.', 'metadata': {'author': 'aristotle', 'love': 'y', 'ethics': 'y'}}, {'_id': '3704304a6fec44498a85d246b862a810', 'content': 'You are what you repeatedly do', 'metadata': {'author': 'aristotle'}}], 'nextPageState': 'KQAAAAEBAAAAIDM3MDQzMDRhNmZlYzQ0NDk4YTg1ZDI0NmI4NjJhODEwAPB////rAA=='}}\n"
          ]
        }
      ],
      "source": [
        "# Checks your collection to verify the documents are embedded.\n",
        "print(vstore.astra_db.collection(\"philocollection\").find())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mslnxHkWt80"
      },
      "source": [
        "### Basic Retrieval\n",
        "\n",
        "Retrieve context from your vector database, and pass it to the model with a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A9fkJhdBWt82",
        "outputId": "92f8ddb7-3a2e-4eb2-8bc3-c88c469dd327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the provided context, it seems that philosophers in this case (specifically Aristotle) are most concerned with ethics and knowledge. Both of these documents mention ethics and knowledge as relevant metadata, suggesting that these topics are important to Aristotle's philosophical work.\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_community.llms import Ollama\n",
        "#load ollama llama3 llm model\n",
        "\n",
        "retriever = vstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Answer the question based only on the supplied context. If you don't know the answer, say you don't know the answer.\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Your answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "model=Ollama(model='llama3:latest')\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke(\"In the given context, what subject are philosophers most concerned with?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VP4EAM9IWt83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'According to the provided context, Aristotle says that true happiness comes from \"gaining insight and growing into your best possible self.\" This is stated in two separate documents with identical page content.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"from where true happiness comes?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE-rpWZyWt85"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZUHxk6GqWt86",
        "nbmake": {
          "post_cell_execute": [
            "# Deletes collection for test suite to allow each test to run with a fresh collection",
            "vstore.delete_collection()"
          ]
        }
      },
      "outputs": [],
      "source": [
        "# WARNING: This will delete the collection and all documents in the collection\n",
        "vstore.delete_collection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64UmysU_Wt87"
      },
      "source": [
        "You now have a fully functioning RAG pipeline! Note that there are several different ways to accomplish this, depending on your input data format, vector store, embedding, model, output type, and more. There are also more advanced RAG techniques that leverage new ingestion, retrieval, and generation patterns.  \n",
        "\n",
        "RAG is a powerful solution used in tandem with the capabilities of LLMs. Check out our other examples for ideas on how you can build innovative solutions using RAGStack!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
